{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb072d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#libraries\n",
    "# ============================================================================\n",
    "# 0. INITIAL SETUP\n",
    "# ============================================================================\n",
    "import os\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "\n",
    "# Scikit-learn\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.linear_model import HuberRegressor\n",
    "from sklearn.ensemble import StackingRegressor, HistGradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "# Tree-based models\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "# Hyperparameter optimization\n",
    "import optuna\n",
    "\n",
    "# SHAP for interpretability\n",
    "import shap\n",
    "\n",
    "# Scipy for statistical tests\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "warnings.filterwarnings('ignore', category=UserWarning)\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d48f26e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "TBI FUNCTIONAL OUTCOME PREDICTION - MODELING PIPELINE\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "STEP 1: Loading Cleaned Data\n",
      "================================================================================\n",
      "Loaded dataset: 13704 rows √ó 137 columns\n",
      "Features: 135 variables\n",
      "Target: FIM_change (range: -87.0 to 106.0)\n",
      "Mean FIM_change: 22.64 ¬± 18.36\n",
      "\n",
      "================================================================================\n",
      "STEP 2: Train/Test Split\n",
      "================================================================================\n",
      "Training Set (NCV): 10963 samples\n",
      "Test Set (Holdout): 2741 samples\n",
      "\n",
      "================================================================================\n",
      "STEP 3: Model Definitions\n",
      "================================================================================\n",
      "Models to train:\n",
      "  1. MeanPredictor\n",
      "  2. HuberRegressor\n",
      "  3. XGBRegressor\n",
      "  4. LGBMRegressor\n",
      "  5. HistGBMRegressor\n",
      "\n",
      "================================================================================\n",
      "STEP 4: Nested Cross-Validation (5 Outer √ó 3 Inner Folds)\n",
      "================================================================================\n",
      "\n",
      "==================================================\n",
      "Training: MeanPredictor\n",
      "==================================================\n",
      "\n",
      "Outer Fold 1/5...\n",
      "  Fold 1: R¬≤=-0.001, MSE=358.148, MAE=14.562, RMSE=18.925\n",
      "\n",
      "Outer Fold 2/5...\n",
      "  Fold 2: R¬≤=-0.001, MSE=335.313, MAE=13.989, RMSE=18.312\n",
      "\n",
      "Outer Fold 3/5...\n",
      "  Fold 3: R¬≤=-0.000, MSE=354.990, MAE=14.451, RMSE=18.841\n",
      "\n",
      "Outer Fold 4/5...\n",
      "  Fold 4: R¬≤=-0.000, MSE=348.854, MAE=14.158, RMSE=18.678\n",
      "\n",
      "Outer Fold 5/5...\n",
      "  Fold 5: R¬≤=-0.000, MSE=316.139, MAE=13.769, RMSE=17.780\n",
      "\n",
      "MeanPredictor - NCV Results:\n",
      "  R¬≤:   -0.000 ¬± 0.000\n",
      "  MAE:  14.186 ¬± 0.326\n",
      "  RMSE: 18.507 ¬± 0.469\n",
      "  MSE:  342.689 ¬± 17.231\n",
      "\n",
      "==================================================\n",
      "Training: HuberRegressor\n",
      "==================================================\n",
      "\n",
      "Outer Fold 1/5...\n",
      "  Fold 1: R¬≤=0.227, MSE=276.615, MAE=12.157, RMSE=16.632\n",
      "\n",
      "Outer Fold 2/5...\n",
      "  Fold 2: R¬≤=0.228, MSE=258.864, MAE=11.869, RMSE=16.089\n",
      "\n",
      "Outer Fold 3/5...\n",
      "  Fold 3: R¬≤=0.216, MSE=278.421, MAE=12.147, RMSE=16.686\n",
      "\n",
      "Outer Fold 4/5...\n",
      "  Fold 4: R¬≤=0.210, MSE=275.402, MAE=12.103, RMSE=16.595\n",
      "\n",
      "Outer Fold 5/5...\n",
      "  Fold 5: R¬≤=0.218, MSE=247.116, MAE=11.589, RMSE=15.720\n",
      "\n",
      "HuberRegressor - NCV Results:\n",
      "  R¬≤:   0.220 ¬± 0.007\n",
      "  MAE:  11.973 ¬± 0.245\n",
      "  RMSE: 16.344 ¬± 0.423\n",
      "  MSE:  267.283 ¬± 13.735\n",
      "\n",
      "==================================================\n",
      "Training: XGBRegressor\n",
      "==================================================\n",
      "\n",
      "Outer Fold 1/5...\n",
      "  Fold 1: R¬≤=0.288, MSE=254.900, MAE=11.592, RMSE=15.966\n",
      "\n",
      "Outer Fold 2/5...\n",
      "  Fold 2: R¬≤=0.284, MSE=239.897, MAE=11.308, RMSE=15.489\n",
      "\n",
      "Outer Fold 3/5...\n",
      "  Fold 3: R¬≤=0.260, MSE=262.536, MAE=11.626, RMSE=16.203\n",
      "\n",
      "Outer Fold 4/5...\n",
      "  Fold 4: R¬≤=0.276, MSE=252.416, MAE=11.532, RMSE=15.888\n",
      "\n",
      "Outer Fold 5/5...\n",
      "  Fold 5: R¬≤=0.288, MSE=225.224, MAE=11.007, RMSE=15.007\n",
      "\n",
      "XGBRegressor - NCV Results:\n",
      "  R¬≤:   0.279 ¬± 0.012\n",
      "  MAE:  11.413 ¬± 0.259\n",
      "  RMSE: 15.710 ¬± 0.470\n",
      "  MSE:  246.995 ¬± 14.643\n",
      "\n",
      "==================================================\n",
      "Training: LGBMRegressor\n",
      "==================================================\n",
      "\n",
      "Outer Fold 1/5...\n",
      "  Fold 1: R¬≤=0.281, MSE=257.293, MAE=11.671, RMSE=16.040\n",
      "\n",
      "Outer Fold 2/5...\n",
      "  Fold 2: R¬≤=0.281, MSE=240.811, MAE=11.390, RMSE=15.518\n",
      "\n",
      "Outer Fold 3/5...\n",
      "  Fold 3: R¬≤=0.247, MSE=267.336, MAE=11.747, RMSE=16.350\n",
      "\n",
      "Outer Fold 4/5...\n",
      "  Fold 4: R¬≤=0.269, MSE=254.934, MAE=11.582, RMSE=15.967\n",
      "\n",
      "Outer Fold 5/5...\n",
      "  Fold 5: R¬≤=0.271, MSE=230.335, MAE=11.099, RMSE=15.177\n",
      "\n",
      "LGBMRegressor - NCV Results:\n",
      "  R¬≤:   0.270 ¬± 0.014\n",
      "  MAE:  11.498 ¬± 0.260\n",
      "  RMSE: 15.810 ¬± 0.463\n",
      "  MSE:  250.142 ¬± 14.570\n",
      "\n",
      "==================================================\n",
      "Training: HistGBMRegressor\n",
      "==================================================\n",
      "\n",
      "Outer Fold 1/5...\n",
      "  Fold 1: R¬≤=0.281, MSE=257.359, MAE=11.630, RMSE=16.042\n",
      "\n",
      "Outer Fold 2/5...\n",
      "  Fold 2: R¬≤=0.281, MSE=241.047, MAE=11.374, RMSE=15.526\n",
      "\n",
      "Outer Fold 3/5...\n",
      "  Fold 3: R¬≤=0.246, MSE=267.707, MAE=11.753, RMSE=16.362\n",
      "\n",
      "Outer Fold 4/5...\n",
      "  Fold 4: R¬≤=0.268, MSE=255.131, MAE=11.636, RMSE=15.973\n",
      "\n",
      "Outer Fold 5/5...\n",
      "  Fold 5: R¬≤=0.275, MSE=229.198, MAE=11.127, RMSE=15.139\n",
      "\n",
      "HistGBMRegressor - NCV Results:\n",
      "  R¬≤:   0.270 ¬± 0.015\n",
      "  MAE:  11.504 ¬± 0.252\n",
      "  RMSE: 15.808 ¬± 0.478\n",
      "  MSE:  250.088 ¬± 15.057\n",
      "\n",
      "================================================================================\n",
      "STEP 5: Model Performance Comparison\n",
      "================================================================================\n",
      "\n",
      "Model Performance Summary (sorted by R¬≤):\n",
      "           Model  Mean_R2_NCV  Mean_MAE_NCV  Mean_RMSE_NCV\n",
      "    XGBRegressor     0.279210     11.413103      15.710450\n",
      "HistGBMRegressor     0.270165     11.504175      15.808395\n",
      "   LGBMRegressor     0.269947     11.497635      15.810451\n",
      "  HuberRegressor     0.219774     11.973019      16.344419\n",
      "   MeanPredictor    -0.000348     14.185858      18.507087\n",
      "\n",
      "üèÜ Best Model: XGBRegressor\n",
      "   Mean R¬≤:   0.279 ¬± 0.012\n",
      "   Mean MAE:  11.413 ¬± 0.259\n",
      "\n",
      "================================================================================\n",
      "STEP 6: Final Evaluation on Holdout Test Set\n",
      "================================================================================\n",
      "\n",
      "XGBRegressor Performance on Holdout Test Set:\n",
      "  R¬≤:   0.283\n",
      "  MSE:  225.528\n",
      "  MAE:  10.976\n",
      "  RMSE: 15.018\n",
      "\n",
      "‚úì Best model and feature list saved\n",
      "\n",
      "================================================================================\n",
      "STEP 7: Statistical Comparison (Bootstrapped 95% CI, n=1000)\n",
      "================================================================================\n",
      "\n",
      "Bootstrapped CI Comparison Results:\n",
      "                      Comparison  R2_diff_mean             R2_CI R2_significant  MAE_diff_mean            MAE_CI MAE_significant\n",
      "   XGBRegressor vs MeanPredictor      0.283674  [0.2526, 0.3159]            Yes       2.629477  [2.3332, 2.9253]             Yes\n",
      "  XGBRegressor vs HuberRegressor      0.073508  [0.0474, 0.1031]            Yes       0.647218  [0.4821, 0.8148]             Yes\n",
      "   XGBRegressor vs LGBMRegressor      0.001051 [-0.0057, 0.0079]             No       0.007039 [-0.0530, 0.0647]              No\n",
      "XGBRegressor vs HistGBMRegressor      0.017733  [0.0093, 0.0260]            Yes       0.177354  [0.1016, 0.2549]             Yes\n",
      "\n",
      "================================================================================\n",
      "STEP 8: Comprehensive Feature Importance Analysis\n",
      "================================================================================\n",
      "\n",
      "Computing feature importance for XGBRegressor...\n",
      "  1Ô∏è‚É£ Permutation Importance...\n",
      "     ‚úì Computed (Top 5: FIMTOTA, LOSRehab, LOSRehabNoInt, FIMMOTA, INJYEAR)\n",
      "  2Ô∏è‚É£ Built-in Feature Importance...\n",
      "     ‚úì Computed (Top 5: FIMTOTA, FIMMOTA, FIMToiletA, FIMDrsdwnA, PrelimOuthm)\n",
      "  3Ô∏è‚É£ SHAP Values...\n",
      "     TreeExplainer failed: could not convert string to float: '[2.259427E1]'...\n",
      "     ‚Üí Falling back to generic shap.Explainer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PermutationExplainer explainer: 101it [00:21,  3.69it/s]                         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     ‚úì SHAP computed using fallback Explainer (Kernel-based)\n",
      "     ‚úì Top 5 SHAP features: FIMTOTA, LOSRehab, LOSRehabNoInt, FIMMOTA, TFCDays\n",
      "\n",
      "‚úì Permutation importance saved\n",
      "‚úì Built-in importance saved\n",
      "‚úì SHAP importance saved\n",
      "\n",
      "================================================================================\n",
      "Top 15 Features by Each Importance Method\n",
      "================================================================================\n",
      "\n",
      "üìä Permutation Importance (Top 15):\n",
      "      feature  importance_mean\n",
      "      FIMTOTA         0.043442\n",
      "     LOSRehab         0.041772\n",
      "LOSRehabNoInt         0.034202\n",
      "      FIMMOTA         0.014450\n",
      "      INJYEAR         0.010391\n",
      "      PTADays         0.010329\n",
      "       LOSTot         0.009074\n",
      " FIMTubTransA         0.006971\n",
      "    RehabPay1         0.006956\n",
      "     AGENoPHI         0.006146\n",
      "     ICDCount         0.004908\n",
      " FIMBedTransA         0.004842\n",
      "    AcutePay1         0.004152\n",
      "   FIMDrsdwnA         0.004151\n",
      "FIMToilTransA         0.004081\n",
      "\n",
      "üìä Built-in Model Importance (Top 15):\n",
      "      feature  importance\n",
      "      FIMTOTA    0.052827\n",
      "      FIMMOTA    0.043303\n",
      "   FIMToiletA    0.042117\n",
      "   FIMDrsdwnA    0.025177\n",
      "  PrelimOuthm    0.017824\n",
      "   EthnicityF    0.017642\n",
      "LOSRehabNoInt    0.016124\n",
      "      FIMCOGA    0.014492\n",
      "     DRSFuncA    0.014449\n",
      "       LOSTot    0.013196\n",
      " FIMTubTransA    0.012068\n",
      "      TFCDays    0.011548\n",
      "     RaceWhtF    0.011459\n",
      "FIMToilTransA    0.011119\n",
      " FIMBedTransA    0.011090\n",
      "\n",
      "üìä SHAP Importance (Top 15):\n",
      "      feature  mean_abs_shap\n",
      "      FIMTOTA       2.540993\n",
      "     LOSRehab       1.963008\n",
      "LOSRehabNoInt       1.494613\n",
      "      FIMMOTA       1.414888\n",
      "      TFCDays       0.961247\n",
      " FIMTubTransA       0.771485\n",
      "    RehabPay1       0.716046\n",
      "      INJYEAR       0.680215\n",
      "     AGENoPHI       0.673802\n",
      "      PTADays       0.657104\n",
      "     ICDCount       0.656604\n",
      "     DRSFuncA       0.650389\n",
      "        Cause       0.623867\n",
      " FIMBedTransA       0.618304\n",
      "   FIMToiletA       0.616243\n",
      "\n",
      "================================================================================\n",
      "STEP 9: Domain-Wise Feature Importance Analysis\n",
      "================================================================================\n",
      "\n",
      "Domain-wise Feature Importance:\n",
      "\n",
      "PERMUTATION:\n",
      "domain\n",
      "Functional_Baseline    0.098787\n",
      "Temporal               0.091876\n",
      "Other                  0.041311\n",
      "Injury_Severity        0.018372\n",
      "Demographics           0.011772\n",
      "Medical_History       -0.000179\n",
      "\n",
      "BUILTIN:\n",
      "domain\n",
      "Functional_Baseline    0.407107\n",
      "Other                  0.384852\n",
      "Demographics           0.081030\n",
      "Temporal               0.061198\n",
      "Injury_Severity        0.061065\n",
      "Medical_History        0.004748\n",
      "\n",
      "SHAP:\n",
      "domain\n",
      "Functional_Baseline    12.157767\n",
      "Other                   6.324070\n",
      "Temporal                5.192226\n",
      "Injury_Severity         2.539857\n",
      "Demographics            2.152945\n",
      "Medical_History         0.046242\n",
      "\n",
      "‚úì Domain-wise importance saved\n",
      "\n",
      "================================================================================\n",
      "STEP 10: Generating Visualizations\n",
      "================================================================================\n",
      "\n",
      "  Plotting model performance comparison...\n",
      "  ‚úì Model comparison plot saved\n",
      "  Plotting permutation importance...\n",
      "  ‚úì Permutation importance plot saved\n",
      "  Plotting built-in importance...\n",
      "  ‚úì Built-in importance plot saved\n",
      "  Plotting SHAP summary...\n",
      "  ‚úì SHAP plots saved\n",
      "  Plotting domain-wise importance...\n",
      "  ‚úì Domain importance plot saved\n",
      "  Plotting predicted vs actual...\n",
      "  ‚úì Predicted vs actual plot saved\n",
      "  Plotting residuals...\n",
      "  ‚úì Residual plots saved\n",
      "\n",
      "================================================================================\n",
      "STEP 11: Final Summary\n",
      "================================================================================\n",
      "\n",
      "üìä MODELING PIPELINE COMPLETE!\n",
      "\n",
      "================================================================================\n",
      "FINAL RESULTS\n",
      "================================================================================\n",
      "\n",
      "üèÜ Best Model: XGBRegressor\n",
      "\n",
      "Nested Cross-Validation (5-fold):\n",
      "  R¬≤:   0.279 ¬± 0.012\n",
      "  MAE:  11.413 ¬± 0.259\n",
      "\n",
      "Final Test Set Performance:\n",
      "  R¬≤:   0.283\n",
      "  MSE:  225.528\n",
      "  MAE:  10.976\n",
      "  RMSE: 15.018\n",
      "\n",
      "================================================================================\n",
      "OUTPUT FILES\n",
      "================================================================================\n",
      "\n",
      "üìÅ Models:\n",
      "  ‚Ä¢ output/models/best_model_final.pkl\n",
      "  ‚Ä¢ output/models/feature_list.pkl\n",
      "\n",
      "üìÅ Tables:\n",
      "  ‚Ä¢ output/tables/model_comparison_table.csv\n",
      "  ‚Ä¢ output/tables/bootstrapped_ci_comparison.csv\n",
      "  ‚Ä¢ output/tables/permutation_importance.csv\n",
      "  ‚Ä¢ output/tables/builtin_importance.csv\n",
      "  ‚Ä¢ output/tables/shap_importance.csv\n",
      "  ‚Ä¢ output/tables/domain_importance.csv\n",
      "  ‚Ä¢ output/tables/final_summary.csv\n",
      "\n",
      "üìÅ Figures:\n",
      "  ‚Ä¢ output/figures/model_comparison_barplots.png\n",
      "  ‚Ä¢ output/figures/permutation_importance_top20.png\n",
      "  ‚Ä¢ output/figures/builtin_importance_top20.png\n",
      "  ‚Ä¢ output/figures/shap_summary_plot.png\n",
      "  ‚Ä¢ output/figures/shap_importance_bar.png\n",
      "  ‚Ä¢ output/figures/domain_importance.png\n",
      "  ‚Ä¢ output/figures/predicted_vs_actual.png\n",
      "  ‚Ä¢ output/figures/residual_analysis.png\n",
      "\n",
      "================================================================================\n",
      "‚úÖ PIPELINE EXECUTION COMPLETE\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "============================================================================\n",
    "01_modeling_pipeline_comprehensive.py\n",
    "============================================================================\n",
    "Purpose: Complete modeling pipeline for TBI functional outcome prediction\n",
    "- Load cleaned data from R preprocessing\n",
    "- Train 6 models with nested CV and Optuna hyperparameter tuning\n",
    "- Perform comprehensive feature importance analysis (PI, Built-in, SHAP)\n",
    "- Statistical comparison with bootstrapped confidence intervals\n",
    "- Save all results and visualizations\n",
    "\n",
    "Author: saumya sharma\n",
    "Date: 17-11-2025\n",
    "Input: data/processed/cleaned_data_for_modeling.csv\n",
    "Output: Models, metrics, importance scores, and visualizations\n",
    "============================================================================\n",
    "\"\"\"\n",
    "\n",
    "# ============================================================================\n",
    "# 0. INITIAL SETUP\n",
    "# ============================================================================\n",
    "\n",
    "\n",
    "# Create output directories\n",
    "os.makedirs(\"output/models\", exist_ok=True)\n",
    "os.makedirs(\"output/figures\", exist_ok=True)\n",
    "os.makedirs(\"output/tables\", exist_ok=True)\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"TBI FUNCTIONAL OUTCOME PREDICTION - MODELING PIPELINE\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# ============================================================================\n",
    "# 1. LOAD DATA\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STEP 1: Loading Cleaned Data\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Load data from R preprocessing output\n",
    "df = pd.read_csv(\"../data/processed/df17nov.csv\")\n",
    "print(f\"Loaded dataset: {df.shape[0]} rows √ó {df.shape[1]} columns\")\n",
    "\n",
    "# Separate features and target\n",
    "X_full = df.drop(columns=['Mod1Id', 'FIM_change'])\n",
    "y_full = df['FIM_change']\n",
    "\n",
    "print(f\"Features: {X_full.shape[1]} variables\")\n",
    "print(f\"Target: FIM_change (range: {y_full.min():.1f} to {y_full.max():.1f})\")\n",
    "print(f\"Mean FIM_change: {y_full.mean():.2f} ¬± {y_full.std():.2f}\")\n",
    "\n",
    "# ============================================================================\n",
    "# 2. TRAIN/TEST SPLIT\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STEP 2: Train/Test Split\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "X_NCV, X_FINAL_TEST, y_NCV, y_FINAL_TEST = train_test_split(\n",
    "    X_full, y_full, test_size=0.2, random_state=RANDOM_SEED, shuffle=True\n",
    ")\n",
    "\n",
    "print(f\"Training Set (NCV): {X_NCV.shape[0]} samples\")\n",
    "print(f\"Test Set (Holdout): {X_FINAL_TEST.shape[0]} samples\")\n",
    "\n",
    "# ============================================================================\n",
    "# 3. DEFINE MODELS AND HYPERPARAMETER SPACES\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STEP 3: Model Definitions\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Define base models\n",
    "MODEL_DEFINITIONS = {\n",
    "    'MeanPredictor': DummyRegressor(strategy='mean'),\n",
    "    'HuberRegressor': HuberRegressor(max_iter=200),\n",
    "    'XGBRegressor': XGBRegressor(random_state=RANDOM_SEED, n_jobs=-1, verbosity=0),\n",
    "    'LGBMRegressor': LGBMRegressor(random_state=RANDOM_SEED, n_jobs=-1, verbosity=-1),\n",
    "    'HistGBMRegressor': HistGradientBoostingRegressor(random_state=RANDOM_SEED),\n",
    "    \n",
    "}\n",
    "\n",
    "print(\"Models to train:\")\n",
    "for i, model_name in enumerate(MODEL_DEFINITIONS.keys(), 1):\n",
    "    print(f\"  {i}. {model_name}\")\n",
    "\n",
    "# ============================================================================\n",
    "# 4. OPTUNA OBJECTIVE FUNCTIONS\n",
    "# ============================================================================\n",
    "\n",
    "def objective_huber(trial, X_train, y_train, inner_cv):\n",
    "    \"\"\"Hyperparameter optimization for HuberRegressor\"\"\"\n",
    "    params = {\n",
    "        'alpha': trial.suggest_float('alpha', 0.0, 1.0),\n",
    "        'epsilon': trial.suggest_float('epsilon', 1.0, 2.0),\n",
    "        'max_iter': 1000\n",
    "    }\n",
    "    \n",
    "    # Create pipeline with imputation and scaling\n",
    "    pipeline = Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy='mean')),\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('huber', HuberRegressor(**params))\n",
    "    ])\n",
    "    \n",
    "    scores = cross_val_score(\n",
    "        pipeline, X_train, y_train, \n",
    "        scoring='neg_mean_squared_error', \n",
    "        cv=inner_cv, \n",
    "        n_jobs=1\n",
    "    )\n",
    "    return -np.mean(scores)\n",
    "\n",
    "\n",
    "def objective_xgb(trial, X_train, y_train, inner_cv):\n",
    "    \"\"\"Hyperparameter optimization for XGBoost\"\"\"\n",
    "    params = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 800),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 12),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.2, log=True),\n",
    "        'subsample': trial.suggest_float('subsample', 0.6, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 1.0),\n",
    "        'random_state': RANDOM_SEED,\n",
    "        'verbosity': 0\n",
    "    }\n",
    "    \n",
    "    # Create pipeline\n",
    "    pipeline = Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy='mean')),\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('xgb', XGBRegressor(**params, n_jobs=1))\n",
    "    ])\n",
    "    \n",
    "    scores = cross_val_score(\n",
    "        pipeline, X_train, y_train,\n",
    "        scoring='neg_mean_squared_error',\n",
    "        cv=inner_cv,\n",
    "        n_jobs=1\n",
    "    )\n",
    "    return -np.mean(scores)\n",
    "\n",
    "\n",
    "def objective_lgbm(trial, X_train, y_train, inner_cv):\n",
    "    \"\"\"Hyperparameter optimization for LightGBM\"\"\"\n",
    "    params = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 800),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 12),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.2, log=True),\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 20, 100),\n",
    "        'random_state': RANDOM_SEED,\n",
    "        'verbosity': -1\n",
    "    }\n",
    "    \n",
    "    pipeline = Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy='mean')),\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('lgbm', LGBMRegressor(**params, n_jobs=1))\n",
    "    ])\n",
    "    \n",
    "    scores = cross_val_score(\n",
    "        pipeline, X_train, y_train,\n",
    "        scoring='neg_mean_squared_error',\n",
    "        cv=inner_cv,\n",
    "        n_jobs=1\n",
    "    )\n",
    "    return -np.mean(scores)\n",
    "\n",
    "\n",
    "def objective_histgbm(trial, X_train, y_train, inner_cv):\n",
    "    \"\"\"Hyperparameter optimization for HistGradientBoosting\"\"\"\n",
    "    params = {\n",
    "        'max_iter': trial.suggest_int('max_iter', 100, 800),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 12),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.2, log=True),\n",
    "        'random_state': RANDOM_SEED\n",
    "    }\n",
    "    \n",
    "    pipeline = Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy='mean')),\n",
    "        ('histgbm', HistGradientBoostingRegressor(**params))\n",
    "    ])\n",
    "    \n",
    "    scores = cross_val_score(\n",
    "        pipeline, X_train, y_train,\n",
    "        scoring='neg_mean_squared_error',\n",
    "        cv=inner_cv,\n",
    "        n_jobs=1\n",
    "    )\n",
    "    return -np.mean(scores)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Map model names to objective functions\n",
    "OBJECTIVE_MAP = {\n",
    "    'HuberRegressor': objective_huber,\n",
    "    'XGBRegressor': objective_xgb,\n",
    "    'LGBMRegressor': objective_lgbm,\n",
    "    'HistGBMRegressor': objective_histgbm,\n",
    "    \n",
    "}\n",
    "\n",
    "# ============================================================================\n",
    "# 5. NESTED CROSS-VALIDATION WITH OPTUNA\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STEP 4: Nested Cross-Validation (5 Outer √ó 3 Inner Folds)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "all_model_results = {}\n",
    "final_models_for_comparison = {}\n",
    "\n",
    "for model_name, base_model in MODEL_DEFINITIONS.items():\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"Training: {model_name}\")\n",
    "    print(f\"{'='*50}\")\n",
    "    \n",
    "    # Outer CV setup\n",
    "    outer_cv = KFold(n_splits=5, shuffle=True, random_state=RANDOM_SEED)\n",
    "    outer_results = []\n",
    "    best_models = []\n",
    "    \n",
    "    for fold_idx, (train_idx, test_idx) in enumerate(outer_cv.split(X_NCV, y_NCV), 1):\n",
    "        print(f\"\\nOuter Fold {fold_idx}/5...\")\n",
    "        \n",
    "        X_train, X_test = X_NCV.iloc[train_idx], X_NCV.iloc[test_idx]\n",
    "        y_train, y_test = y_NCV.iloc[train_idx], y_NCV.iloc[test_idx]\n",
    "        \n",
    "        # Inner CV for hyperparameter tuning\n",
    "        inner_cv = KFold(n_splits=3, shuffle=True, random_state=RANDOM_SEED)\n",
    "        \n",
    "        if model_name == 'MeanPredictor':\n",
    "            # Baseline model - no tuning needed\n",
    "            pipeline = Pipeline([\n",
    "                ('imputer', SimpleImputer(strategy='mean')),\n",
    "                ('mean', DummyRegressor(strategy='mean'))\n",
    "            ])\n",
    "            best_params = {}\n",
    "        \n",
    "        else:\n",
    "            # Hyperparameter tuning with Optuna\n",
    "            study = optuna.create_study(\n",
    "                direction='minimize',\n",
    "                sampler=optuna.samplers.TPESampler(seed=RANDOM_SEED)\n",
    "            )\n",
    "            \n",
    "            objective_with_data = lambda trial: OBJECTIVE_MAP[model_name](\n",
    "                trial, X_train, y_train, inner_cv\n",
    "            )\n",
    "            \n",
    "            study.optimize(objective_with_data, n_trials=20, show_progress_bar=False)\n",
    "            best_params = study.best_params\n",
    "            \n",
    "            # Cast integer parameters\n",
    "            int_params = ['n_estimators', 'max_depth', 'num_leaves', 'max_iter',\n",
    "                         'hist_max_iter', 'hist_max_depth', 'lgbm_n_estimators',\n",
    "                         'lgbm_max_depth', 'lgbm_num_leaves', 'xgb_n_estimators',\n",
    "                         'xgb_max_depth']\n",
    "            for k in int_params:\n",
    "                if k in best_params:\n",
    "                    best_params[k] = int(best_params[k])\n",
    "            \n",
    "            # Build pipeline with best parameters\n",
    "            if model_name == 'HuberRegressor':\n",
    "                pipeline = Pipeline([\n",
    "                    ('imputer', SimpleImputer(strategy='mean')),\n",
    "                    ('scaler', StandardScaler()),\n",
    "                    ('huber', HuberRegressor(**best_params, max_iter=1000))\n",
    "                ])\n",
    "            \n",
    "            elif model_name == 'XGBRegressor':\n",
    "                pipeline = Pipeline([\n",
    "                    ('imputer', SimpleImputer(strategy='mean')),\n",
    "                    ('scaler', StandardScaler()),\n",
    "                    ('xgb', XGBRegressor(**best_params, random_state=RANDOM_SEED, n_jobs=-1, verbosity=0))\n",
    "                ])\n",
    "            \n",
    "            elif model_name == 'LGBMRegressor':\n",
    "                pipeline = Pipeline([\n",
    "                    ('imputer', SimpleImputer(strategy='mean')),\n",
    "                    ('scaler', StandardScaler()),\n",
    "                    ('lgbm', LGBMRegressor(**best_params, random_state=RANDOM_SEED, n_jobs=-1, verbosity=-1))\n",
    "                ])\n",
    "            \n",
    "            elif model_name == 'HistGBMRegressor':\n",
    "                pipeline = Pipeline([\n",
    "                    ('imputer', SimpleImputer(strategy='mean')),\n",
    "                    ('histgbm', HistGradientBoostingRegressor(**best_params, random_state=RANDOM_SEED))\n",
    "                ])\n",
    "            \n",
    "            \n",
    "        \n",
    "        # Train and evaluate\n",
    "        pipeline.fit(X_train, y_train)\n",
    "        best_models.append(pipeline)\n",
    "        \n",
    "        y_pred = pipeline.predict(X_test)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        mse = mean_squared_error(y_test, y_pred)\n",
    "        mae = mean_absolute_error(y_test, y_pred)\n",
    "        rmse = np.sqrt(mse)\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        \n",
    "        outer_results.append({\n",
    "            'fold': fold_idx,\n",
    "            'mse': mse,\n",
    "            'mae': mae,\n",
    "            'rmse': rmse,\n",
    "            'r2': r2,\n",
    "            'params': best_params\n",
    "        })\n",
    "        \n",
    "        print(f\"  Fold {fold_idx}: R¬≤={r2:.3f}, MSE={mse:.3f}, MAE={mae:.3f}, RMSE={rmse:.3f}\")\n",
    "    \n",
    "    # Aggregate results\n",
    "    outer_df = pd.DataFrame(outer_results)\n",
    "    all_model_results[model_name] = {\n",
    "        'models': best_models,\n",
    "        'results': outer_df,\n",
    "        'mean_mse': outer_df['mse'].mean(),\n",
    "        'std_mse': outer_df['mse'].std(),\n",
    "        'mean_mae': outer_df['mae'].mean(),\n",
    "        'std_mae': outer_df['mae'].std(),\n",
    "        'mean_rmse': outer_df['rmse'].mean(),\n",
    "        'std_rmse': outer_df['rmse'].std(),\n",
    "        'mean_r2': outer_df['r2'].mean(),\n",
    "        'std_r2': outer_df['r2'].std()\n",
    "    }\n",
    "    \n",
    "    print(f\"\\n{model_name} - NCV Results:\")\n",
    "    print(f\"  R¬≤:   {all_model_results[model_name]['mean_r2']:.3f} ¬± {all_model_results[model_name]['std_r2']:.3f}\")\n",
    "    print(f\"  MAE:  {all_model_results[model_name]['mean_mae']:.3f} ¬± {all_model_results[model_name]['std_mae']:.3f}\")\n",
    "    print(f\"  RMSE: {all_model_results[model_name]['mean_rmse']:.3f} ¬± {all_model_results[model_name]['std_rmse']:.3f}\")\n",
    "    print(f\"  MSE:  {all_model_results[model_name]['mean_mse']:.3f} ¬± {all_model_results[model_name]['std_mse']:.3f}\")\n",
    "    \n",
    "    # Train final model on entire NCV set with best parameters from best fold\n",
    "    best_fold_result = outer_df.sort_values('r2', ascending=False).iloc[0]\n",
    "    best_fold_params = best_fold_result['params']\n",
    "    \n",
    "    # Reconstruct pipeline with best parameters\n",
    "    if model_name == 'MeanPredictor':\n",
    "        final_pipeline = Pipeline([\n",
    "            ('imputer', SimpleImputer(strategy='mean')),\n",
    "            ('mean', DummyRegressor(strategy='mean'))\n",
    "        ])\n",
    "    elif model_name == 'HuberRegressor':\n",
    "        final_pipeline = Pipeline([\n",
    "            ('imputer', SimpleImputer(strategy='mean')),\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('huber', HuberRegressor(**best_fold_params, max_iter=1000))\n",
    "        ])\n",
    "    elif model_name == 'XGBRegressor':\n",
    "        final_pipeline = Pipeline([\n",
    "            ('imputer', SimpleImputer(strategy='mean')),\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('xgb', XGBRegressor(**best_fold_params, random_state=RANDOM_SEED, n_jobs=-1, verbosity=0))\n",
    "        ])\n",
    "    elif model_name == 'LGBMRegressor':\n",
    "        final_pipeline = Pipeline([\n",
    "            ('imputer', SimpleImputer(strategy='mean')),\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('lgbm', LGBMRegressor(**best_fold_params, random_state=RANDOM_SEED, n_jobs=-1, verbosity=-1))\n",
    "        ])\n",
    "    elif model_name == 'HistGBMRegressor':\n",
    "        final_pipeline = Pipeline([\n",
    "            ('imputer', SimpleImputer(strategy='mean')),\n",
    "            ('histgbm', HistGradientBoostingRegressor(**best_fold_params, random_state=RANDOM_SEED))\n",
    "        ])\n",
    "    \n",
    "        \n",
    "    \n",
    "    final_pipeline.fit(X_NCV, y_NCV)\n",
    "    final_models_for_comparison[model_name] = final_pipeline\n",
    "\n",
    "# ============================================================================\n",
    "# 6. MODEL COMPARISON TABLE\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STEP 5: Model Performance Comparison\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "comparison_list = []\n",
    "for model_name, info in all_model_results.items():\n",
    "    comparison_list.append({\n",
    "        'Model': model_name,\n",
    "        'Num_Features': len(X_full.columns),\n",
    "        'Mean_MSE_NCV': info['mean_mse'],\n",
    "        'Std_MSE_NCV': info['std_mse'],\n",
    "        'Mean_MAE_NCV': info['mean_mae'],\n",
    "        'Std_MAE_NCV': info['std_mae'],\n",
    "        'Mean_RMSE_NCV': info['mean_rmse'],\n",
    "        'Std_RMSE_NCV': info['std_rmse'],\n",
    "        'Mean_R2_NCV': info['mean_r2'],\n",
    "        'Std_R2_NCV': info['std_r2']\n",
    "    })\n",
    "\n",
    "comparison_df = pd.DataFrame(comparison_list).sort_values('Mean_R2_NCV', ascending=False)\n",
    "comparison_df.to_csv(\"output/tables/model_comparison_table.csv\", index=False)\n",
    "\n",
    "print(\"\\nModel Performance Summary (sorted by R¬≤):\")\n",
    "print(comparison_df[['Model', 'Mean_R2_NCV', 'Mean_MAE_NCV', 'Mean_RMSE_NCV']].to_string(index=False))\n",
    "\n",
    "best_model_name = comparison_df.iloc[0]['Model']\n",
    "print(f\"\\nüèÜ Best Model: {best_model_name}\")\n",
    "print(f\"   Mean R¬≤:   {comparison_df.iloc[0]['Mean_R2_NCV']:.3f} ¬± {comparison_df.iloc[0]['Std_R2_NCV']:.3f}\")\n",
    "print(f\"   Mean MAE:  {comparison_df.iloc[0]['Mean_MAE_NCV']:.3f} ¬± {comparison_df.iloc[0]['Std_MAE_NCV']:.3f}\")\n",
    "\n",
    "# ============================================================================\n",
    "# 7. FINAL EVALUATION ON HOLDOUT TEST SET\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STEP 6: Final Evaluation on Holdout Test Set\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "best_model_instance = final_models_for_comparison[best_model_name]\n",
    "y_pred_test = best_model_instance.predict(X_FINAL_TEST)\n",
    "\n",
    "mse_test = mean_squared_error(y_FINAL_TEST, y_pred_test)\n",
    "mae_test = mean_absolute_error(y_FINAL_TEST, y_pred_test)\n",
    "rmse_test = np.sqrt(mse_test)\n",
    "r2_test = r2_score(y_FINAL_TEST, y_pred_test)\n",
    "\n",
    "print(f\"\\n{best_model_name} Performance on Holdout Test Set:\")\n",
    "print(f\"  R¬≤:   {r2_test:.3f}\")\n",
    "print(f\"  MSE:  {mse_test:.3f}\")\n",
    "print(f\"  MAE:  {mae_test:.3f}\")\n",
    "print(f\"  RMSE: {rmse_test:.3f}\")\n",
    "\n",
    "# Save best model\n",
    "joblib.dump(best_model_instance, \"output/models/best_model_final.pkl\")\n",
    "joblib.dump(list(X_full.columns), \"output/models/feature_list.pkl\")\n",
    "print(\"\\n‚úì Best model and feature list saved\")\n",
    "\n",
    "# ============================================================================\n",
    "# 8. BOOTSTRAPPED CONFIDENCE INTERVALS\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STEP 7: Statistical Comparison (Bootstrapped 95% CI, n=1000)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "def calculate_ci_difference_regression(y_true, y_pred1, y_pred2, alpha=0.05, n_bootstrap=1000, random_state=42):\n",
    "    \"\"\"Calculate bootstrapped confidence intervals for model comparison\"\"\"\n",
    "    np.random.seed(random_state)\n",
    "    n = len(y_true)\n",
    "    y_true = np.array(y_true)\n",
    "    y_pred1 = np.array(y_pred1)\n",
    "    y_pred2 = np.array(y_pred2)\n",
    "    \n",
    "    r2_diffs = []\n",
    "    mae_diffs = []\n",
    "    \n",
    "    for _ in range(n_bootstrap):\n",
    "        idx = np.random.choice(n, n, replace=True)\n",
    "        r2_diff = r2_score(y_true[idx], y_pred1[idx]) - r2_score(y_true[idx], y_pred2[idx])\n",
    "        mae_diff = mean_absolute_error(y_true[idx], y_pred2[idx]) - mean_absolute_error(y_true[idx], y_pred1[idx])\n",
    "        r2_diffs.append(r2_diff)\n",
    "        mae_diffs.append(mae_diff)\n",
    "    \n",
    "    return {\n",
    "        'R2_diff_mean': np.mean(r2_diffs),\n",
    "        'R2_CI_lower': np.percentile(r2_diffs, alpha/2*100),\n",
    "        'R2_CI_upper': np.percentile(r2_diffs, (1-alpha/2)*100),\n",
    "        'R2_significant': 'Yes' if np.percentile(r2_diffs, alpha/2*100) > 0 else 'No',\n",
    "        'MAE_diff_mean': np.mean(mae_diffs),\n",
    "        'MAE_CI_lower': np.percentile(mae_diffs, alpha/2*100),\n",
    "        'MAE_CI_upper': np.percentile(mae_diffs, (1-alpha/2)*100),\n",
    "        'MAE_significant': 'Yes' if np.percentile(mae_diffs, alpha/2*100) > 0 else 'No'\n",
    "    }\n",
    "\n",
    "# Compare best model against all others\n",
    "pred_best = best_model_instance.predict(X_FINAL_TEST)\n",
    "\n",
    "ci_results = []\n",
    "for compare_name, model_instance in final_models_for_comparison.items():\n",
    "    if compare_name == best_model_name:\n",
    "        continue\n",
    "    \n",
    "    pred_compare = model_instance.predict(X_FINAL_TEST)\n",
    "    ci_stats = calculate_ci_difference_regression(y_FINAL_TEST, pred_best, pred_compare)\n",
    "    \n",
    "    ci_results.append({\n",
    "        'Comparison': f\"{best_model_name} vs {compare_name}\",\n",
    "        'R2_diff_mean': ci_stats['R2_diff_mean'],\n",
    "        'R2_CI': f\"[{ci_stats['R2_CI_lower']:.4f}, {ci_stats['R2_CI_upper']:.4f}]\",\n",
    "        'R2_significant': ci_stats['R2_significant'],\n",
    "        'MAE_diff_mean': ci_stats['MAE_diff_mean'],\n",
    "        'MAE_CI': f\"[{ci_stats['MAE_CI_lower']:.4f}, {ci_stats['MAE_CI_upper']:.4f}]\",\n",
    "        'MAE_significant': ci_stats['MAE_significant']\n",
    "    })\n",
    "\n",
    "ci_df = pd.DataFrame(ci_results)\n",
    "ci_df.to_csv(\"output/tables/bootstrapped_ci_comparison.csv\", index=False)\n",
    "\n",
    "print(\"\\nBootstrapped CI Comparison Results:\")\n",
    "print(ci_df.to_string(index=False))\n",
    "\n",
    "# ============================================================================\n",
    "# 9. COMPREHENSIVE FEATURE IMPORTANCE ANALYSIS\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STEP 8: Comprehensive Feature Importance Analysis\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "def compute_feature_importance(model, X, y, X_test, y_test, model_name, top_n=20, seed=42):\n",
    "    \"\"\"\n",
    "    Compute three types of feature importance:\n",
    "    1. Permutation Importance (on test set)\n",
    "    2. Built-in Model Feature Importance (if available)\n",
    "    3. SHAP values (with TreeExplainer fallback to KernelExplainer)\n",
    "    \"\"\"\n",
    "    print(f\"\\nComputing feature importance for {model_name}...\")\n",
    "    \n",
    "    # Extract the actual model from pipeline\n",
    "    if hasattr(model, 'named_steps'):\n",
    "        # It's a pipeline - get the last step\n",
    "        model_obj = model.steps[-1][1]\n",
    "    else:\n",
    "        model_obj = model\n",
    "    \n",
    "    # -------------------------------------------------------------------------\n",
    "    # 1. PERMUTATION IMPORTANCE \n",
    "    # -------------------------------------------------------------------------\n",
    "    print(\"  1Ô∏è‚É£ Permutation Importance...\")\n",
    "    perm_imp = permutation_importance(\n",
    "        model, X_test, y_test,\n",
    "        n_repeats=10,\n",
    "        random_state=seed,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    perm_imp_df = pd.DataFrame({\n",
    "        'feature': X.columns,\n",
    "        'importance_mean': perm_imp.importances_mean,\n",
    "        'importance_std': perm_imp.importances_std\n",
    "    }).sort_values('importance_mean', ascending=False)\n",
    "    \n",
    "    print(f\"     ‚úì Computed (Top 5: {', '.join(perm_imp_df.head(5)['feature'].values)})\")\n",
    "    \n",
    "    # -------------------------------------------------------------------------\n",
    "    # 2. BUILT-IN MODEL FEATURE IMPORTANCE\n",
    "    # -------------------------------------------------------------------------\n",
    "    print(\"  2Ô∏è‚É£ Built-in Feature Importance...\")\n",
    "    builtin_imp = None\n",
    "    \n",
    "    # Check if model has feature_importances_ attribute\n",
    "    if hasattr(model_obj, 'feature_importances_'):\n",
    "        builtin_imp = pd.DataFrame({\n",
    "            'feature': X.columns,\n",
    "            'importance': model_obj.feature_importances_\n",
    "        }).sort_values('importance', ascending=False)\n",
    "        print(f\"     ‚úì Computed (Top 5: {', '.join(builtin_imp.head(5)['feature'].values)})\")\n",
    "    \n",
    "    # For stacked models, try to get from final estimator\n",
    "    elif hasattr(model_obj, 'final_estimator_') and hasattr(model_obj.final_estimator_, 'feature_importances_'):\n",
    "        builtin_imp = pd.DataFrame({\n",
    "            'feature': X.columns,\n",
    "            'importance': model_obj.final_estimator_.feature_importances_\n",
    "        }).sort_values('importance', ascending=False)\n",
    "        print(f\"     ‚úì Computed from final estimator\")\n",
    "    \n",
    "    # For linear models (Huber), use coefficients\n",
    "    elif hasattr(model_obj, 'coef_'):\n",
    "        builtin_imp = pd.DataFrame({\n",
    "            'feature': X.columns,\n",
    "            'importance': np.abs(model_obj.coef_)\n",
    "        }).sort_values('importance', ascending=False)\n",
    "        print(f\"     ‚úì Computed from coefficients\")\n",
    "    \n",
    "    else:\n",
    "        print(f\"     ‚ö† Not available for {model_name}\")\n",
    "    \n",
    "    # -------------------------------------------------------------------------\n",
    "    # 3. SHAP VALUES (with TreeExplainer ‚Üí generic Explainer fallback)\n",
    "    # -------------------------------------------------------------------------\n",
    "    print(\"  3Ô∏è‚É£ SHAP Values...\")\n",
    "    \n",
    "    X_sample = X.sample(n=min(100, len(X)), random_state=seed)\n",
    "    X_background = X.sample(n=min(50, len(X)), random_state=seed)\n",
    "    \n",
    "    shap_values = None\n",
    "    shap_imp_df = None\n",
    "    \n",
    "    try:\n",
    "        # Try TreeExplainer first (fast for tree-based models)\n",
    "        explainer = shap.TreeExplainer(model_obj)\n",
    "        shap_values = explainer.shap_values(X_sample)\n",
    "        print(\"     ‚úì SHAP computed using TreeExplainer\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"     TreeExplainer failed: {str(e)[:50]}...\")\n",
    "        print(\"     ‚Üí Falling back to generic shap.Explainer\")\n",
    "        \n",
    "        try:\n",
    "            # Safe prediction wrapper\n",
    "            def model_predict(data):\n",
    "                return model.predict(data)\n",
    "            \n",
    "            # Fallback to generic SHAP explainer (Kernel-based)\n",
    "            explainer = shap.Explainer(model_predict, X_background)\n",
    "            shap_obj = explainer(X_sample)\n",
    "            shap_values = shap_obj.values\n",
    "            print(\"     ‚úì SHAP computed using fallback Explainer (Kernel-based)\")\n",
    "        \n",
    "        except Exception as e2:\n",
    "            print(f\"     ‚ùå SHAP computation failed: {str(e2)[:50]}\")\n",
    "            shap_values = None\n",
    "    \n",
    "    # Build SHAP importance dataframe\n",
    "    if shap_values is not None:\n",
    "        # Handle different SHAP output formats\n",
    "        if isinstance(shap_values, list):\n",
    "            # Multi-output case\n",
    "            shap_array = np.mean(np.abs(shap_values), axis=0)\n",
    "        else:\n",
    "            shap_array = shap_values\n",
    "        \n",
    "        # Ensure 2D array\n",
    "        if shap_array.ndim == 3:\n",
    "            shap_array = shap_array.mean(axis=0)\n",
    "        \n",
    "        shap_imp_df = pd.DataFrame({\n",
    "            'feature': X.columns,\n",
    "            'mean_abs_shap': np.abs(shap_array).mean(axis=0)\n",
    "        }).sort_values('mean_abs_shap', ascending=False)\n",
    "        \n",
    "        print(f\"     ‚úì Top 5 SHAP features: {', '.join(shap_imp_df.head(5)['feature'].values)}\")\n",
    "    \n",
    "    return {\n",
    "        'permutation': perm_imp_df,\n",
    "        'builtin': builtin_imp,\n",
    "        'shap': shap_imp_df,\n",
    "        'shap_values': shap_values,\n",
    "        'X_sample': X_sample\n",
    "    }\n",
    "\n",
    "\n",
    "# Compute importance for best model\n",
    "importance_results = compute_feature_importance(\n",
    "    model=best_model_instance,\n",
    "    X=X_NCV,\n",
    "    y=y_NCV,\n",
    "    X_test=X_FINAL_TEST,\n",
    "    y_test=y_FINAL_TEST,\n",
    "    model_name=best_model_name,\n",
    "    top_n=20,\n",
    "    seed=RANDOM_SEED\n",
    ")\n",
    "\n",
    "# Save importance results\n",
    "importance_results['permutation'].to_csv(\"output/tables/permutation_importance.csv\", index=False)\n",
    "print(\"\\n‚úì Permutation importance saved\")\n",
    "\n",
    "if importance_results['builtin'] is not None:\n",
    "    importance_results['builtin'].to_csv(\"output/tables/builtin_importance.csv\", index=False)\n",
    "    print(\"‚úì Built-in importance saved\")\n",
    "\n",
    "if importance_results['shap'] is not None:\n",
    "    importance_results['shap'].to_csv(\"output/tables/shap_importance.csv\", index=False)\n",
    "    print(\"‚úì SHAP importance saved\")\n",
    "\n",
    "# Print top features from each method\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Top 15 Features by Each Importance Method\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\nüìä Permutation Importance (Top 15):\")\n",
    "print(importance_results['permutation'].head(15)[['feature', 'importance_mean']].to_string(index=False))\n",
    "\n",
    "if importance_results['builtin'] is not None:\n",
    "    print(\"\\nüìä Built-in Model Importance (Top 15):\")\n",
    "    print(importance_results['builtin'].head(15)[['feature', 'importance']].to_string(index=False))\n",
    "\n",
    "if importance_results['shap'] is not None:\n",
    "    print(\"\\nüìä SHAP Importance (Top 15):\")\n",
    "    print(importance_results['shap'].head(15)[['feature', 'mean_abs_shap']].to_string(index=False))\n",
    "\n",
    "# ============================================================================\n",
    "# 10. DOMAIN-WISE FEATURE IMPORTANCE\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STEP 9: Domain-Wise Feature Importance Analysis\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Define domain mapping (customize based on your features)\n",
    "# This is a template - you'll need to update based on your actual feature names\n",
    "DOMAIN_MAPPING = {\n",
    "    'Demographics': ['AGE', 'GENDER', 'RACE', 'ETHNIC', 'MARITAL', 'EDUC'],\n",
    "    'Injury_Severity': ['GCS', 'PTA', 'TFC', 'LOC', 'INJURY'],\n",
    "    'Functional_Baseline': ['FIM', 'DRS', 'MOTOR', 'COGN'],\n",
    "    'Medical_History': ['DIABETES', 'HYPERTENSION', 'CARDIAC', 'NEURO'],\n",
    "    'Temporal': ['LOS', 'REHAB', 'THERAPY', 'INTERVENTION'],\n",
    "    'Other': []  # Catch-all for features not matching above\n",
    "}\n",
    "\n",
    "def assign_domain(feature_name):\n",
    "    \"\"\"Assign feature to domain based on substring matching\"\"\"\n",
    "    feature_upper = feature_name.upper()\n",
    "    for domain, keywords in DOMAIN_MAPPING.items():\n",
    "        if domain == 'Other':\n",
    "            continue\n",
    "        for keyword in keywords:\n",
    "            if keyword in feature_upper:\n",
    "                return domain\n",
    "    return 'Other'\n",
    "\n",
    "# Add domain column to importance dataframes\n",
    "for imp_type in ['permutation', 'builtin', 'shap']:\n",
    "    if importance_results[imp_type] is not None:\n",
    "        importance_results[imp_type]['domain'] = importance_results[imp_type]['feature'].apply(assign_domain)\n",
    "\n",
    "# Aggregate importance by domain\n",
    "domain_importance = {}\n",
    "\n",
    "if importance_results['permutation'] is not None:\n",
    "    domain_importance['permutation'] = importance_results['permutation'].groupby('domain')['importance_mean'].sum().sort_values(ascending=False)\n",
    "\n",
    "if importance_results['builtin'] is not None:\n",
    "    domain_importance['builtin'] = importance_results['builtin'].groupby('domain')['importance'].sum().sort_values(ascending=False)\n",
    "\n",
    "if importance_results['shap'] is not None:\n",
    "    domain_importance['shap'] = importance_results['shap'].groupby('domain')['mean_abs_shap'].sum().sort_values(ascending=False)\n",
    "\n",
    "# Print domain-wise importance\n",
    "print(\"\\nDomain-wise Feature Importance:\")\n",
    "for imp_type, domain_imp in domain_importance.items():\n",
    "    print(f\"\\n{imp_type.upper()}:\")\n",
    "    print(domain_imp.to_string())\n",
    "\n",
    "# Save domain importance\n",
    "domain_importance_df = pd.DataFrame(domain_importance)\n",
    "domain_importance_df.to_csv(\"output/tables/domain_importance.csv\")\n",
    "print(\"\\n‚úì Domain-wise importance saved\")\n",
    "\n",
    "# ============================================================================\n",
    "# 11. VISUALIZATIONS\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STEP 10: Generating Visualizations\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# 11a. Model Performance Comparison Plot\n",
    "# -------------------------------------------------------------------------\n",
    "print(\"\\n  Plotting model performance comparison...\")\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(20, 6))\n",
    "\n",
    "plot_df = comparison_df[comparison_df['Model'] != 'MeanPredictor']\n",
    "metrics = [\n",
    "    ('Mean_R2_NCV', 'Mean R¬≤ (NCV)', 'green'),\n",
    "    ('Mean_MAE_NCV', 'Mean Absolute Error (NCV)', 'orange'),\n",
    "    ('Mean_MSE_NCV', 'Mean Squared Error (NCV)', 'red')\n",
    "]\n",
    "\n",
    "for i, (metric, title, color) in enumerate(metrics):\n",
    "    sns.barplot(x='Model', y=metric, data=plot_df, ax=axes[i], color=color)\n",
    "    \n",
    "    # Add error bars\n",
    "    std_metric = metric.replace('Mean', 'Std')\n",
    "    axes[i].errorbar(\n",
    "        x=range(len(plot_df)),\n",
    "        y=plot_df[metric],\n",
    "        yerr=plot_df[std_metric],\n",
    "        fmt='none',\n",
    "        color='black',\n",
    "        capsize=5\n",
    "    )\n",
    "    \n",
    "    axes[i].set_xlabel('Model', fontsize=12)\n",
    "    axes[i].set_ylabel(title, fontsize=12)\n",
    "    axes[i].tick_params(axis='x', rotation=45)\n",
    "    axes[i].set_title(title, fontsize=14)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"output/figures/model_comparison_barplots.png\", dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "print(\"  ‚úì Model comparison plot saved\")\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# 11b. Permutation Importance Plot\n",
    "# -------------------------------------------------------------------------\n",
    "print(\"  Plotting permutation importance...\")\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "top_20_perm = importance_results['permutation'].head(20)\n",
    "sns.barplot(\n",
    "    x='importance_mean',\n",
    "    y='feature',\n",
    "    data=top_20_perm,\n",
    "    palette='viridis'\n",
    ")\n",
    "plt.errorbar(\n",
    "    x=top_20_perm['importance_mean'],\n",
    "    y=range(len(top_20_perm)),\n",
    "    xerr=top_20_perm['importance_std'],\n",
    "    fmt='none',\n",
    "    color='black',\n",
    "    capsize=3\n",
    ")\n",
    "plt.xlabel('Permutation Importance', fontsize=12)\n",
    "plt.ylabel('Feature', fontsize=12)\n",
    "plt.title(f'Top 20 Features - Permutation Importance ({best_model_name})', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"output/figures/permutation_importance_top20.png\", dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "print(\"  ‚úì Permutation importance plot saved\")\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# 11c. Built-in Importance Plot (if available)\n",
    "# -------------------------------------------------------------------------\n",
    "if importance_results['builtin'] is not None:\n",
    "    print(\"  Plotting built-in importance...\")\n",
    "    \n",
    "    plt.figure(figsize=(12, 8))\n",
    "    top_20_builtin = importance_results['builtin'].head(20)\n",
    "    \n",
    "    # Color by sign for linear models, otherwise single color\n",
    "    if 'coef_' in str(type(best_model_instance.steps[-1][1])):\n",
    "        colors = ['red' if x < 0 else 'green' for x in top_20_builtin['importance']]\n",
    "    else:\n",
    "        colors = 'magma'\n",
    "    \n",
    "    sns.barplot(\n",
    "        x='importance',\n",
    "        y='feature',\n",
    "        data=top_20_builtin,\n",
    "        palette=colors if isinstance(colors, list) else colors\n",
    "    )\n",
    "    plt.xlabel('Built-in Importance', fontsize=12)\n",
    "    plt.ylabel('Feature', fontsize=12)\n",
    "    plt.title(f'Top 20 Features - Built-in Importance ({best_model_name})', fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"output/figures/builtin_importance_top20.png\", dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(\"  ‚úì Built-in importance plot saved\")\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# 11d. SHAP Summary Plot\n",
    "# -------------------------------------------------------------------------\n",
    "if importance_results['shap_values'] is not None:\n",
    "    print(\"  Plotting SHAP summary...\")\n",
    "    \n",
    "    # SHAP summary plot (dot plot)\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    shap.summary_plot(\n",
    "        importance_results['shap_values'],\n",
    "        importance_results['X_sample'],\n",
    "        show=False,\n",
    "        max_display=20\n",
    "    )\n",
    "    plt.title(f'SHAP Summary Plot ({best_model_name})', fontsize=14, pad=20)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"output/figures/shap_summary_plot.png\", dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    # SHAP bar plot\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    shap.summary_plot(\n",
    "        importance_results['shap_values'],\n",
    "        importance_results['X_sample'],\n",
    "        plot_type=\"bar\",\n",
    "        show=False,\n",
    "        max_display=20\n",
    "    )\n",
    "    plt.gca().set_xlabel(\"Mean Absolute SHAP Value (Average Impact on Prediction)\", fontsize=12)\n",
    "    plt.title(f'SHAP Feature Importance', fontsize=14, pad=20)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"output/figures/shap_importance_bar.png\", dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(\"  ‚úì SHAP plots saved\")\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# 11e. Domain Importance Plot\n",
    "# -------------------------------------------------------------------------\n",
    "print(\"  Plotting domain-wise importance...\")\n",
    "\n",
    "fig, axes = plt.subplots(1, len(domain_importance), figsize=(6*len(domain_importance), 6))\n",
    "if len(domain_importance) == 1:\n",
    "    axes = [axes]\n",
    "\n",
    "for i, (imp_type, domain_imp) in enumerate(domain_importance.items()):\n",
    "    domain_imp.plot(kind='barh', ax=axes[i], color='steelblue')\n",
    "    axes[i].set_xlabel('Total Importance', fontsize=12)\n",
    "    axes[i].set_ylabel('Domain', fontsize=12)\n",
    "    axes[i].set_title(f'Domain Importance - {imp_type.upper()}', fontsize=14)\n",
    "    axes[i].invert_yaxis()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"output/figures/domain_importance.png\", dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "print(\"  ‚úì Domain importance plot saved\")\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# 11f. Predicted vs Actual Plot\n",
    "# -------------------------------------------------------------------------\n",
    "print(\"  Plotting predicted vs actual...\")\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.scatter(y_FINAL_TEST, y_pred_test, alpha=0.5, edgecolors='k', linewidth=0.5)\n",
    "plt.plot([y_FINAL_TEST.min(), y_FINAL_TEST.max()],\n",
    "         [y_FINAL_TEST.min(), y_FINAL_TEST.max()],\n",
    "         'r--', lw=2, label='Perfect Prediction')\n",
    "plt.xlabel('Actual FIM Change', fontsize=12)\n",
    "plt.ylabel('Predicted FIM Change', fontsize=12)\n",
    "plt.title(f'Predicted vs Actual FIM Change ({best_model_name})\\nTest Set R¬≤ = {r2_test:.3f}',\n",
    "          fontsize=14)\n",
    "plt.legend(fontsize=10)\n",
    "plt.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"output/figures/predicted_vs_actual.png\", dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "print(\"  ‚úì Predicted vs actual plot saved\")\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# 11g. Residual Plot\n",
    "# -------------------------------------------------------------------------\n",
    "print(\"  Plotting residuals...\")\n",
    "\n",
    "residuals = y_FINAL_TEST - y_pred_test\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Residual scatter\n",
    "axes[0].scatter(y_pred_test, residuals, alpha=0.5, edgecolors='k', linewidth=0.5)\n",
    "axes[0].axhline(y=0, color='r', linestyle='--', lw=2)\n",
    "axes[0].set_xlabel('Predicted FIM Change', fontsize=12)\n",
    "axes[0].set_ylabel('Residuals', fontsize=12)\n",
    "axes[0].set_title('Residual Plot', fontsize=14)\n",
    "axes[0].grid(alpha=0.3)\n",
    "\n",
    "# Residual histogram\n",
    "axes[1].hist(residuals, bins=30, edgecolor='black', alpha=0.7)\n",
    "axes[1].axvline(x=0, color='r', linestyle='--', lw=2)\n",
    "axes[1].set_xlabel('Residuals', fontsize=12)\n",
    "axes[1].set_ylabel('Frequency', fontsize=12)\n",
    "axes[1].set_title('Residual Distribution', fontsize=14)\n",
    "axes[1].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"output/figures/residual_analysis.png\", dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "print(\"  ‚úì Residual plots saved\")\n",
    "\n",
    "# ============================================================================\n",
    "# 12. FINAL SUMMARY & EXPORT\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STEP 11: Final Summary\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Create comprehensive summary\n",
    "summary = {\n",
    "    'Best_Model': best_model_name,\n",
    "    'Num_Features': len(X_full.columns),\n",
    "    'Training_Samples': len(X_NCV),\n",
    "    'Test_Samples': len(X_FINAL_TEST),\n",
    "    'NCV_R2_mean': comparison_df.iloc[0]['Mean_R2_NCV'],\n",
    "    'NCV_R2_std': comparison_df.iloc[0]['Std_R2_NCV'],\n",
    "    'NCV_MAE_mean': comparison_df.iloc[0]['Mean_MAE_NCV'],\n",
    "    'NCV_MAE_std': comparison_df.iloc[0]['Std_MAE_NCV'],\n",
    "    'Test_R2': r2_test,\n",
    "    'Test_MSE': mse_test,\n",
    "    'Test_MAE': mae_test,\n",
    "    'Test_RMSE': rmse_test\n",
    "}\n",
    "\n",
    "summary_df = pd.DataFrame([summary])\n",
    "summary_df.to_csv(\"output/tables/final_summary.csv\", index=False)\n",
    "\n",
    "print(\"\\nüìä MODELING PIPELINE COMPLETE!\")\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"FINAL RESULTS\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nüèÜ Best Model: {best_model_name}\")\n",
    "print(f\"\\nNested Cross-Validation (5-fold):\")\n",
    "print(f\"  R¬≤:   {summary['NCV_R2_mean']:.3f} ¬± {summary['NCV_R2_std']:.3f}\")\n",
    "print(f\"  MAE:  {summary['NCV_MAE_mean']:.3f} ¬± {summary['NCV_MAE_std']:.3f}\")\n",
    "print(f\"\\nFinal Test Set Performance:\")\n",
    "print(f\"  R¬≤:   {summary['Test_R2']:.3f}\")\n",
    "print(f\"  MSE:  {summary['Test_MSE']:.3f}\")\n",
    "print(f\"  MAE:  {summary['Test_MAE']:.3f}\")\n",
    "print(f\"  RMSE: {summary['Test_RMSE']:.3f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"OUTPUT FILES\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\nüìÅ Models:\")\n",
    "print(\"  ‚Ä¢ output/models/best_model_final.pkl\")\n",
    "print(\"  ‚Ä¢ output/models/feature_list.pkl\")\n",
    "print(\"\\nüìÅ Tables:\")\n",
    "print(\"  ‚Ä¢ output/tables/model_comparison_table.csv\")\n",
    "print(\"  ‚Ä¢ output/tables/bootstrapped_ci_comparison.csv\")\n",
    "print(\"  ‚Ä¢ output/tables/permutation_importance.csv\")\n",
    "if importance_results['builtin'] is not None:\n",
    "    print(\"  ‚Ä¢ output/tables/builtin_importance.csv\")\n",
    "if importance_results['shap'] is not None:\n",
    "    print(\"  ‚Ä¢ output/tables/shap_importance.csv\")\n",
    "print(\"  ‚Ä¢ output/tables/domain_importance.csv\")\n",
    "print(\"  ‚Ä¢ output/tables/final_summary.csv\")\n",
    "print(\"\\nüìÅ Figures:\")\n",
    "print(\"  ‚Ä¢ output/figures/model_comparison_barplots.png\")\n",
    "print(\"  ‚Ä¢ output/figures/permutation_importance_top20.png\")\n",
    "if importance_results['builtin'] is not None:\n",
    "    print(\"  ‚Ä¢ output/figures/builtin_importance_top20.png\")\n",
    "if importance_results['shap_values'] is not None:\n",
    "    print(\"  ‚Ä¢ output/figures/shap_summary_plot.png\")\n",
    "    print(\"  ‚Ä¢ output/figures/shap_importance_bar.png\")\n",
    "print(\"  ‚Ä¢ output/figures/domain_importance.png\")\n",
    "print(\"  ‚Ä¢ output/figures/predicted_vs_actual.png\")\n",
    "print(\"  ‚Ä¢ output/figures/residual_analysis.png\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"‚úÖ PIPELINE EXECUTION COMPLETE\")\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
