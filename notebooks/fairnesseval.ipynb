{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7e39585b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "FAIRNESS ANALYSIS AND BIAS MITIGATION PIPELINE\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "STEP 1: Loading Model and Test Set\n",
      "================================================================================\n",
      "âœ“ Loaded model from output/models/best_model_final.pkl\n",
      "âœ“ Loaded dataset: 13704 rows Ã— 137 columns\n",
      "\n",
      "âœ“ Test set size: 2741 samples\n",
      "  (Training set: 10963 samples - NOT used for fairness analysis)\n",
      "\n",
      "================================================================================\n",
      "STEP 2: Defining Demographic Subgroups\n",
      "================================================================================\n",
      "âœ“ Age groups: ['<30', '30-50', '50+']\n",
      "âœ“ Sex: Female, Male\n",
      "âœ“ Employment: Employed, Student, Retired, Unemployed, Other\n",
      "âœ“ Income: <$20k, $20k-$50k, $50k-$100k, $100k+, Unknown\n",
      "âœ“ Education: High School or Less, Associate, Bachelors, Graduate, Unknown\n",
      "\n",
      "âœ“ Total subgroups defined: 5\n",
      "\n",
      "================================================================================\n",
      "STEP 3: Generating Original Predictions\n",
      "================================================================================\n",
      "âœ“ Predictions generated for 2741 test samples\n",
      "  Mean residual: -0.321\n",
      "  Std residual: 14.824\n",
      "\n",
      "================================================================================\n",
      "STEP 4: Bias Detection (ANOVA/T-Test)\n",
      "================================================================================\n",
      "\n",
      "--- Testing AgeGroup ---\n",
      "  ANOVA: F = 4.363, p = 0.0128\n",
      "  âœ“ SIGNIFICANT BIAS DETECTED (p = 0.0128)\n",
      "\n",
      "--- Testing Sex ---\n",
      "  t-test: t = 0.670, p = 0.5030\n",
      "  âœ“ No significant bias (p = 0.5030)\n",
      "\n",
      "--- Testing Employment ---\n",
      "  ANOVA: F = 3.854, p = 0.0040\n",
      "  âœ“ SIGNIFICANT BIAS DETECTED (p = 0.0040)\n",
      "\n",
      "--- Testing Income ---\n",
      "  ANOVA: F = 1.255, p = 0.2854\n",
      "  âœ“ No significant bias (p = 0.2854)\n",
      "\n",
      "--- Testing Education ---\n",
      "  ANOVA: F = 0.270, p = 0.8972\n",
      "  âœ“ No significant bias (p = 0.8972)\n",
      "\n",
      "================================================================================\n",
      "BIAS DETECTION SUMMARY\n",
      "================================================================================\n",
      "  Variable   Test  Statistic  p_value Significant\n",
      "  AgeGroup  ANOVA   4.362957 0.012833         Yes\n",
      "       Sex t-test   0.669901 0.503041          No\n",
      "Employment  ANOVA   3.854361 0.003975         Yes\n",
      "    Income  ANOVA   1.255365 0.285385          No\n",
      " Education  ANOVA   0.270274 0.897231          No\n",
      "\n",
      "âš  Variables requiring calibration: AgeGroup, Employment\n",
      "\n",
      "================================================================================\n",
      "STEP 5: Post-Hoc Calibration\n",
      "================================================================================\n",
      "\n",
      "--- Calibrating AgeGroup ---\n",
      "  Mean residuals before calibration:\n",
      "    <30: 0.056\n",
      "    30-50: 0.685\n",
      "    50+: -1.419\n",
      "  âœ“ Calibration applied for AgeGroup\n",
      "\n",
      "--- Calibrating Employment ---\n",
      "  Mean residuals before calibration:\n",
      "    Employed: -0.096\n",
      "    Other: 0.583\n",
      "    Retired: -2.749\n",
      "    Student: -0.271\n",
      "    Unemployed: 1.006\n",
      "  âœ“ Calibration applied for Employment\n",
      "\n",
      "âœ“ Calibration complete\n",
      "  Original mean residual: -0.321\n",
      "  Calibrated mean residual: 0.184\n",
      "\n",
      "================================================================================\n",
      "STEP 6: Verification (Re-run ANOVA After Calibration)\n",
      "================================================================================\n",
      "\n",
      "--- Verifying AgeGroup ---\n",
      "  Before: F = 4.363, p = 0.0128\n",
      "  After:  F = 1.492, p = 0.2250\n",
      "  âœ“ Bias successfully eliminated (p = 0.2250 >= 0.05)\n",
      "\n",
      "--- Verifying Employment ---\n",
      "  Before: F = 3.854, p = 0.0040\n",
      "  After:  F = 0.343, p = 0.8492\n",
      "  âœ“ Bias successfully eliminated (p = 0.8492 >= 0.05)\n",
      "\n",
      "================================================================================\n",
      "VERIFICATION SUMMARY\n",
      "================================================================================\n",
      "  Variable  F_before  p_before  F_after  p_after Bias_Eliminated\n",
      "  AgeGroup  4.362957  0.012833 1.492357 0.225032             Yes\n",
      "Employment  3.854361  0.003975 0.342682 0.849239             Yes\n",
      "\n",
      "================================================================================\n",
      "STEP 7: Bootstrap Comparison (n=5,000)\n",
      "================================================================================\n",
      "Running 5000 bootstrap iterations...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saumy\\AppData\\Local\\Temp\\ipykernel_17564\\3116176886.py:282: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  bias_by_group = df_test.groupby(grp_col)['Residual_original'].mean()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Completed 1000/5000 iterations...\n",
      "  Completed 2000/5000 iterations...\n",
      "  Completed 3000/5000 iterations...\n",
      "  Completed 4000/5000 iterations...\n",
      "  Completed 5000/5000 iterations...\n",
      "\n",
      "================================================================================\n",
      "BOOTSTRAP RESULTS\n",
      "================================================================================\n",
      "\n",
      "MAE Difference (Calibrated - Original):\n",
      "  Mean: -0.0408\n",
      "  95% CI: [-0.1000, 0.0213]\n",
      "  Interpretation: No significant change\n",
      "\n",
      "RÂ² Difference (Calibrated - Original):\n",
      "  Mean: 0.0039\n",
      "  95% CI: [-0.0029, 0.0107]\n",
      "  Interpretation: No significant change\n",
      "\n",
      "================================================================================\n",
      "STEP 8: Computing Metrics Per Subgroup\n",
      "================================================================================\n",
      "âœ“ Computed metrics for 20 subgroups\n",
      "\n",
      "Sample of subgroup metrics:\n",
      "  Subgroup   Category    N  MAE_original  MAE_calibrated  R2_original  R2_calibrated  MeanResidual_original  MeanResidual_calibrated\n",
      "  AgeGroup        50+  788     11.461699       11.463366     0.220628       0.221406              -1.418887                 1.006101\n",
      "  AgeGroup      30-50  811     10.761700       10.698086     0.309174       0.314892               0.685186                -0.013302\n",
      "  AgeGroup        <30 1041     10.076342       10.073014     0.361241       0.362124               0.056290                -0.108200\n",
      "       Sex       Male 2019     10.804895       10.752896     0.286559       0.292510              -0.208140                 0.202361\n",
      "       Sex     Female  722     10.884478       10.875250     0.338624       0.337020              -0.636110                 0.131902\n",
      "Employment    Retired  429     13.309941       13.143779     0.197607       0.208383              -2.749286                 0.942626\n",
      "Employment Unemployed  252     11.273505       11.246047     0.242014       0.247707               1.005600                -0.070795\n",
      "Employment      Other  398     10.696873       10.628858     0.230652       0.232944               0.582506                 0.004339\n",
      "Employment   Employed 1516     10.079789       10.075138     0.354633       0.356431              -0.096117                 0.080638\n",
      "Employment    Student  146     10.852541       10.857179     0.289250       0.289255              -0.271221                -0.046027\n",
      "\n",
      "================================================================================\n",
      "STEP 9: Generating Visualizations\n",
      "================================================================================\n",
      "\n",
      "  Creating plots for AgeGroup...\n",
      "\n",
      "  Creating plots for Sex...\n",
      "\n",
      "  Creating plots for Employment...\n",
      "\n",
      "  Creating plots for Income...\n",
      "\n",
      "  Creating plots for Education...\n",
      "\n",
      "âœ“ All visualizations saved\n",
      "\n",
      "================================================================================\n",
      "STEP 10: Saving Final Outputs\n",
      "================================================================================\n",
      "âœ“ Saved predictions comparison\n",
      "âœ“ Saved calibration adjustments\n",
      "\n",
      "================================================================================\n",
      "FAIRNESS ANALYSIS COMPLETE\n",
      "================================================================================\n",
      "\n",
      "ðŸ“Š Summary:\n",
      "  â€¢ Test set size: 2741\n",
      "  â€¢ Demographics analyzed: 5\n",
      "  â€¢ Variables with significant bias: 2\n",
      "  â€¢ Calibration applied to: AgeGroup, Employment\n",
      "  â€¢ Bootstrap iterations: 5000\n",
      "\n",
      "ðŸ“ Output files saved to:\n",
      "  â€¢ output/fairness/tables/\n",
      "    - bias_detection_results.csv\n",
      "    - calibration_verification.csv\n",
      "    - bootstrap_comparison.csv\n",
      "    - subgroup_metrics.csv\n",
      "    - predictions_comparison.csv\n",
      "    - calibration_adjustments.csv\n",
      "  â€¢ output/fairness/figures/\n",
      "    - bias_comparison_[variable].png (for each demographic)\n",
      "\n",
      "================================================================================\n",
      "âœ… PIPELINE EXECUTION COMPLETE\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "============================================================================\n",
    "02_fairness_analysis_and_calibration.py\n",
    "============================================================================\n",
    "Purpose: Comprehensive fairness analysis and bias mitigation for TBI model\n",
    "- Loadthe test set \n",
    "- Detect bias across ALL demographics (age, sex, employment, income, education)\n",
    "- Calibrate ONLY variables with significant bias (p < 0.05)\n",
    "- Bootstrap comparison (5,000 iterations) to assess calibration impact\n",
    "- Generate visualizations and reports\n",
    "\n",
    "Author: saumya sharma\n",
    "Date: 24 dec 2025\n",
    "Input: \n",
    "  - output/models/best_model_final.pkl (trained model)\n",
    "  - data/processed/df17nov.csv (full dataset)\n",
    "Output: \n",
    "  - Bias detection results\n",
    "  - Calibrated predictions\n",
    "  - Bootstrap comparison results\n",
    "  - Fairness visualizations\n",
    "============================================================================\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import joblib\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.utils import resample\n",
    "from scipy.stats import ttest_ind, f_oneway\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "# Create output directories\n",
    "os.makedirs(\"output/fairness\", exist_ok=True)\n",
    "os.makedirs(\"output/fairness/figures\", exist_ok=True)\n",
    "os.makedirs(\"output/fairness/tables\", exist_ok=True)\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"FAIRNESS ANALYSIS AND BIAS MITIGATION PIPELINE\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# ============================================================================\n",
    "# 1. LOAD MODEL AND RECREATE TEST SET\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STEP 1: Loading Model and Test Set\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Load model\n",
    "best_model_path = \"output/models/best_model_final.pkl\"\n",
    "best_model_instance = joblib.load(best_model_path)\n",
    "print(f\"âœ“ Loaded model from {best_model_path}\")\n",
    "\n",
    "# Load full dataset\n",
    "filepath = \"../data/processed/df17nov.csv\"\n",
    "df = pd.read_csv(filepath)\n",
    "print(f\"âœ“ Loaded dataset: {df.shape[0]} rows Ã— {df.shape[1]} columns\")\n",
    "\n",
    "# Separate features and target\n",
    "target_col = 'FIM_change'\n",
    "X_full = df.drop(columns=[target_col, 'Mod1Id'], errors='ignore')\n",
    "y_full = df[target_col]\n",
    "\n",
    "# CRITICAL: Recreate the EXACT same train/test split from modeling pipeline\n",
    "# This ensures we only use TEST SET for fairness analysis\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_full, y_full, \n",
    "    test_size=0.2, \n",
    "    random_state=RANDOM_SEED, \n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "print(f\"\\nâœ“ Test set size: {X_test.shape[0]} samples\")\n",
    "print(f\"  (Training set: {X_train.shape[0]} samples - NOT used for fairness analysis)\")\n",
    "\n",
    "# Ensure feature alignment with model\n",
    "model_features = best_model_instance.feature_names_in_\n",
    "X_test = X_test[model_features]\n",
    "\n",
    "# Create test dataframe for analysis\n",
    "df_test = X_test.copy()\n",
    "df_test['FIM_change'] = y_test.values\n",
    "\n",
    "# ============================================================================\n",
    "# 2. DEFINE DEMOGRAPHIC SUBGROUPS\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STEP 2: Defining Demographic Subgroups\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Age groups\n",
    "age_bins = [0, 30, 50, 100]\n",
    "age_labels = ['<30', '30-50', '50+']\n",
    "df_test['AgeGroup'] = pd.cut(df_test['AGENoPHI'], bins=age_bins, labels=age_labels)\n",
    "print(f\"âœ“ Age groups: {age_labels}\")\n",
    "\n",
    "# Sex\n",
    "df_test['Sex'] = df_test['SexF'].map({1: 'Female', 2: 'Male'})\n",
    "print(f\"âœ“ Sex: Female, Male\")\n",
    "\n",
    "# Employment (simplified to avoid too many small categories)\n",
    "emp_map = {\n",
    "    5: 'Employed',\n",
    "    2: 'Student',\n",
    "    3: 'Student',\n",
    "    9: 'Retired',\n",
    "    12: 'Retired',\n",
    "    15: 'Retired',\n",
    "    10: 'Unemployed',\n",
    "    13: 'Unemployed',\n",
    "}\n",
    "df_test['Employment'] = df_test['Emp1'].map(emp_map).fillna('Other')\n",
    "print(f\"âœ“ Employment: Employed, Student, Retired, Unemployed, Other\")\n",
    "\n",
    "# Income (grouped into broader categories)\n",
    "def categorize_income(earn_code):\n",
    "    if pd.isna(earn_code) or earn_code in [666, 777, 888, 999]:\n",
    "        return 'Unknown'\n",
    "    elif earn_code in [1, 2]:\n",
    "        return '<$20k'\n",
    "    elif earn_code in [3, 4, 5]:\n",
    "        return '$20k-$50k'\n",
    "    elif earn_code in [6, 7, 8, 9, 10]:\n",
    "        return '$50k-$100k'\n",
    "    elif earn_code == 11:\n",
    "        return '$100k+'\n",
    "    else:\n",
    "        return 'Unknown'\n",
    "\n",
    "df_test['Income'] = df_test['Earn'].apply(categorize_income)\n",
    "print(f\"âœ“ Income: <$20k, $20k-$50k, $50k-$100k, $100k+, Unknown\")\n",
    "\n",
    "# Education (grouped)\n",
    "def categorize_education(edu_years):\n",
    "    if pd.isna(edu_years) or edu_years in [666, 999]:\n",
    "        return 'Unknown'\n",
    "    elif edu_years <= 12:\n",
    "        return 'High School or Less'\n",
    "    elif edu_years in [13, 14]:\n",
    "        return 'Associate'\n",
    "    elif edu_years in [15, 16]:\n",
    "        return 'Bachelors'\n",
    "    elif edu_years >= 17:\n",
    "        return 'Graduate'\n",
    "    else:\n",
    "        return 'Unknown'\n",
    "\n",
    "df_test['Education'] = df_test['EduYears'].apply(categorize_education)\n",
    "print(f\"âœ“ Education: High School or Less, Associate, Bachelors, Graduate, Unknown\")\n",
    "\n",
    "# Subgroup dictionary\n",
    "subgroups = {\n",
    "    'AgeGroup': df_test['AgeGroup'],\n",
    "    'Sex': df_test['Sex'],\n",
    "    'Employment': df_test['Employment'],\n",
    "    'Income': df_test['Income'],\n",
    "    'Education': df_test['Education']\n",
    "}\n",
    "\n",
    "print(f\"\\nâœ“ Total subgroups defined: {len(subgroups)}\")\n",
    "\n",
    "# ============================================================================\n",
    "# 3. GENERATE ORIGINAL PREDICTIONS\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STEP 3: Generating Original Predictions\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "y_pred_original = best_model_instance.predict(X_test)\n",
    "residuals_original = y_pred_original - y_test.values\n",
    "\n",
    "df_test['y_pred_original'] = y_pred_original\n",
    "df_test['Residual_original'] = residuals_original\n",
    "\n",
    "print(f\"âœ“ Predictions generated for {len(y_pred_original)} test samples\")\n",
    "print(f\"  Mean residual: {residuals_original.mean():.3f}\")\n",
    "print(f\"  Std residual: {residuals_original.std():.3f}\")\n",
    "\n",
    "# ============================================================================\n",
    "# 4. BIAS DETECTION: ANOVA/T-TEST FOR ALL DEMOGRAPHICS\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STEP 4: Bias Detection (ANOVA/T-Test)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "bias_results = []\n",
    "variables_to_calibrate = []\n",
    "\n",
    "for grp_name, grp_col in subgroups.items():\n",
    "    print(f\"\\n--- Testing {grp_name} ---\")\n",
    "    \n",
    "    # Get unique categories (drop NaN)\n",
    "    categories = grp_col.dropna().unique()\n",
    "    \n",
    "    # Skip if only 1 category\n",
    "    if len(categories) < 2:\n",
    "        print(f\"  âš  Skipped: Only {len(categories)} category\")\n",
    "        continue\n",
    "    \n",
    "    # Collect residuals by category\n",
    "    groups = [residuals_original[grp_col == cat] for cat in categories]\n",
    "    \n",
    "    # Filter out empty groups\n",
    "    groups = [g for g in groups if len(g) > 0]\n",
    "    \n",
    "    if len(groups) < 2:\n",
    "        print(f\"  âš  Skipped: Not enough non-empty groups\")\n",
    "        continue\n",
    "    \n",
    "    # Statistical test\n",
    "    if len(groups) == 2:\n",
    "        # Binary variable: t-test\n",
    "        t_stat, p_val = ttest_ind(groups[0], groups[1], equal_var=False)\n",
    "        test_stat = t_stat\n",
    "        test_name = \"t-test\"\n",
    "        print(f\"  t-test: t = {t_stat:.3f}, p = {p_val:.4f}\")\n",
    "    else:\n",
    "        # Multi-category: ANOVA\n",
    "        f_stat, p_val = f_oneway(*groups)\n",
    "        test_stat = f_stat\n",
    "        test_name = \"ANOVA\"\n",
    "        print(f\"  ANOVA: F = {f_stat:.3f}, p = {p_val:.4f}\")\n",
    "    \n",
    "    # Record results\n",
    "    bias_results.append({\n",
    "        'Variable': grp_name,\n",
    "        'Test': test_name,\n",
    "        'Statistic': test_stat,\n",
    "        'p_value': p_val,\n",
    "        'Significant': 'Yes' if p_val < 0.05 else 'No'\n",
    "    })\n",
    "    \n",
    "    # Mark for calibration if significant\n",
    "    if p_val < 0.05:\n",
    "        variables_to_calibrate.append(grp_name)\n",
    "        print(f\"  âœ“ SIGNIFICANT BIAS DETECTED (p = {p_val:.4f})\")\n",
    "    else:\n",
    "        print(f\"  âœ“ No significant bias (p = {p_val:.4f})\")\n",
    "\n",
    "# Save bias detection results\n",
    "bias_df = pd.DataFrame(bias_results)\n",
    "bias_df.to_csv(\"output/fairness/tables/bias_detection_results.csv\", index=False)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"BIAS DETECTION SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "print(bias_df.to_string(index=False))\n",
    "\n",
    "if len(variables_to_calibrate) > 0:\n",
    "    print(f\"\\nâš  Variables requiring calibration: {', '.join(variables_to_calibrate)}\")\n",
    "else:\n",
    "    print(\"\\nâœ“ No variables require calibration (no significant bias detected)\")\n",
    "\n",
    "# ============================================================================\n",
    "# 5. POST-HOC CALIBRATION (ONLY FOR BIASED VARIABLES)\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STEP 5: Post-Hoc Calibration\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Start with original predictions\n",
    "df_test['y_pred_calibrated'] = df_test['y_pred_original'].copy()\n",
    "\n",
    "calibration_applied = {}\n",
    "\n",
    "if len(variables_to_calibrate) == 0:\n",
    "    print(\"âœ“ No calibration needed (no significant bias detected)\")\n",
    "else:\n",
    "    for var_name in variables_to_calibrate:\n",
    "        print(f\"\\n--- Calibrating {var_name} ---\")\n",
    "        \n",
    "        grp_col = subgroups[var_name]\n",
    "        \n",
    "        # Compute mean residual per category\n",
    "        bias_by_group = df_test.groupby(grp_col)['Residual_original'].mean()\n",
    "        \n",
    "        print(\"  Mean residuals before calibration:\")\n",
    "        for cat, bias_val in bias_by_group.items():\n",
    "            print(f\"    {cat}: {bias_val:.3f}\")\n",
    "        \n",
    "        # Apply calibration: subtract group bias\n",
    "        def calibrate_prediction(row):\n",
    "            if pd.isna(row[var_name]):\n",
    "                return row['y_pred_calibrated']  # Don't calibrate missing\n",
    "            else:\n",
    "                return row['y_pred_calibrated'] - bias_by_group[row[var_name]]\n",
    "        \n",
    "        df_test['y_pred_calibrated'] = df_test.apply(\n",
    "            lambda row: calibrate_prediction(row), axis=1\n",
    "        )\n",
    "        \n",
    "        # Store calibration info\n",
    "        calibration_applied[var_name] = bias_by_group.to_dict()\n",
    "        \n",
    "        print(f\"  âœ“ Calibration applied for {var_name}\")\n",
    "\n",
    "# Recalculate residuals after calibration\n",
    "df_test['Residual_calibrated'] = df_test['y_pred_calibrated'] - y_test.values\n",
    "\n",
    "print(f\"\\nâœ“ Calibration complete\")\n",
    "print(f\"  Original mean residual: {df_test['Residual_original'].mean():.3f}\")\n",
    "print(f\"  Calibrated mean residual: {df_test['Residual_calibrated'].mean():.3f}\")\n",
    "\n",
    "# ============================================================================\n",
    "# 6. RE-RUN ANOVA TO VERIFY BIAS REDUCTION\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STEP 6: Verification (Re-run ANOVA After Calibration)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "if len(variables_to_calibrate) == 0:\n",
    "    print(\"âœ“ Skipped (no calibration was applied)\")\n",
    "else:\n",
    "    verification_results = []\n",
    "    \n",
    "    for var_name in variables_to_calibrate:\n",
    "        print(f\"\\n--- Verifying {var_name} ---\")\n",
    "        \n",
    "        grp_col = subgroups[var_name]\n",
    "        categories = grp_col.dropna().unique()\n",
    "        \n",
    "        # Original residuals\n",
    "        groups_orig = [df_test[grp_col == cat]['Residual_original'] for cat in categories]\n",
    "        groups_orig = [g for g in groups_orig if len(g) > 0]\n",
    "        \n",
    "        # Calibrated residuals\n",
    "        groups_cal = [df_test[grp_col == cat]['Residual_calibrated'] for cat in categories]\n",
    "        groups_cal = [g for g in groups_cal if len(g) > 0]\n",
    "        \n",
    "        # ANOVA\n",
    "        if len(groups_orig) >= 2:\n",
    "            f_orig, p_orig = f_oneway(*groups_orig)\n",
    "            f_cal, p_cal = f_oneway(*groups_cal)\n",
    "            \n",
    "            print(f\"  Before: F = {f_orig:.3f}, p = {p_orig:.4f}\")\n",
    "            print(f\"  After:  F = {f_cal:.3f}, p = {p_cal:.4f}\")\n",
    "            \n",
    "            if p_cal >= 0.05:\n",
    "                print(f\"  âœ“ Bias successfully eliminated (p = {p_cal:.4f} >= 0.05)\")\n",
    "            else:\n",
    "                print(f\"  âš  Residual bias remains (p = {p_cal:.4f} < 0.05)\")\n",
    "            \n",
    "            verification_results.append({\n",
    "                'Variable': var_name,\n",
    "                'F_before': f_orig,\n",
    "                'p_before': p_orig,\n",
    "                'F_after': f_cal,\n",
    "                'p_after': p_cal,\n",
    "                'Bias_Eliminated': 'Yes' if p_cal >= 0.05 else 'No'\n",
    "            })\n",
    "    \n",
    "    # Save verification results\n",
    "    if verification_results:\n",
    "        verification_df = pd.DataFrame(verification_results)\n",
    "        verification_df.to_csv(\"output/fairness/tables/calibration_verification.csv\", index=False)\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"VERIFICATION SUMMARY\")\n",
    "        print(\"=\"*80)\n",
    "        print(verification_df.to_string(index=False))\n",
    "\n",
    "# ============================================================================\n",
    "# 7. BOOTSTRAP COMPARISON (5,000 ITERATIONS)\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STEP 7: Bootstrap Comparison (n=5,000)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "y_true = y_test.values\n",
    "y_pred_orig = df_test['y_pred_original'].values\n",
    "y_pred_cal = df_test['y_pred_calibrated'].values\n",
    "\n",
    "N_BOOTSTRAP = 5000\n",
    "mae_diffs = []\n",
    "r2_diffs = []\n",
    "\n",
    "print(f\"Running {N_BOOTSTRAP} bootstrap iterations...\")\n",
    "\n",
    "for i in range(N_BOOTSTRAP):\n",
    "    if (i + 1) % 1000 == 0:\n",
    "        print(f\"  Completed {i + 1}/{N_BOOTSTRAP} iterations...\")\n",
    "    \n",
    "    # Resample with replacement\n",
    "    idx = resample(np.arange(len(y_true)), replace=True, random_state=RANDOM_SEED + i)\n",
    "    \n",
    "    y_boot = y_true[idx]\n",
    "    y_orig_boot = y_pred_orig[idx]\n",
    "    y_cal_boot = y_pred_cal[idx]\n",
    "    \n",
    "    # Compute metrics\n",
    "    mae_orig = mean_absolute_error(y_boot, y_orig_boot)\n",
    "    mae_cal = mean_absolute_error(y_boot, y_cal_boot)\n",
    "    r2_orig = r2_score(y_boot, y_orig_boot)\n",
    "    r2_cal = r2_score(y_boot, y_cal_boot)\n",
    "    \n",
    "    # Store differences (Calibrated - Original)\n",
    "    mae_diffs.append(mae_cal - mae_orig)\n",
    "    r2_diffs.append(r2_cal - r2_orig)\n",
    "\n",
    "# Compute statistics\n",
    "mae_diff_mean = np.mean(mae_diffs)\n",
    "r2_diff_mean = np.mean(r2_diffs)\n",
    "\n",
    "mae_ci = (np.percentile(mae_diffs, 2.5), np.percentile(mae_diffs, 97.5))\n",
    "r2_ci = (np.percentile(r2_diffs, 2.5), np.percentile(r2_diffs, 97.5))\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"BOOTSTRAP RESULTS\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nMAE Difference (Calibrated - Original):\")\n",
    "print(f\"  Mean: {mae_diff_mean:.4f}\")\n",
    "print(f\"  95% CI: [{mae_ci[0]:.4f}, {mae_ci[1]:.4f}]\")\n",
    "print(f\"  Interpretation: {'No significant change' if mae_ci[0] < 0 < mae_ci[1] else 'Significant change'}\")\n",
    "\n",
    "print(f\"\\nRÂ² Difference (Calibrated - Original):\")\n",
    "print(f\"  Mean: {r2_diff_mean:.4f}\")\n",
    "print(f\"  95% CI: [{r2_ci[0]:.4f}, {r2_ci[1]:.4f}]\")\n",
    "print(f\"  Interpretation: {'No significant change' if r2_ci[0] < 0 < r2_ci[1] else 'Significant change'}\")\n",
    "\n",
    "# Save bootstrap results\n",
    "bootstrap_results = pd.DataFrame({\n",
    "    'Metric': ['MAE_diff', 'R2_diff'],\n",
    "    'Mean': [mae_diff_mean, r2_diff_mean],\n",
    "    'CI_lower': [mae_ci[0], r2_ci[0]],\n",
    "    'CI_upper': [mae_ci[1], r2_ci[1]],\n",
    "    'Significant': [\n",
    "        'No' if mae_ci[0] < 0 < mae_ci[1] else 'Yes',\n",
    "        'No' if r2_ci[0] < 0 < r2_ci[1] else 'Yes'\n",
    "    ]\n",
    "})\n",
    "bootstrap_results.to_csv(\"output/fairness/tables/bootstrap_comparison.csv\", index=False)\n",
    "\n",
    "# ============================================================================\n",
    "# 8. COMPUTE METRICS PER SUBGROUP\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STEP 8: Computing Metrics Per Subgroup\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "metrics_list = []\n",
    "\n",
    "for grp_name, grp_col in subgroups.items():\n",
    "    for category in grp_col.unique():\n",
    "        if pd.isna(category):\n",
    "            continue\n",
    "        \n",
    "        idx = grp_col == category\n",
    "        \n",
    "        if idx.sum() == 0:\n",
    "            continue\n",
    "        \n",
    "        y_true_grp = y_test.values[idx]\n",
    "        y_pred_orig_grp = y_pred_orig[idx]\n",
    "        y_pred_cal_grp = y_pred_cal[idx]\n",
    "        \n",
    "        metrics_list.append({\n",
    "            'Subgroup': grp_name,\n",
    "            'Category': category,\n",
    "            'N': len(y_true_grp),\n",
    "            'MAE_original': mean_absolute_error(y_true_grp, y_pred_orig_grp),\n",
    "            'MAE_calibrated': mean_absolute_error(y_true_grp, y_pred_cal_grp),\n",
    "            'R2_original': r2_score(y_true_grp, y_pred_orig_grp),\n",
    "            'R2_calibrated': r2_score(y_true_grp, y_pred_cal_grp),\n",
    "            'MeanResidual_original': (y_pred_orig_grp - y_true_grp).mean(),\n",
    "            'MeanResidual_calibrated': (y_pred_cal_grp - y_true_grp).mean()\n",
    "        })\n",
    "\n",
    "metrics_df = pd.DataFrame(metrics_list)\n",
    "metrics_df.to_csv(\"output/fairness/tables/subgroup_metrics.csv\", index=False)\n",
    "\n",
    "print(f\"âœ“ Computed metrics for {len(metrics_df)} subgroups\")\n",
    "print(\"\\nSample of subgroup metrics:\")\n",
    "print(metrics_df.head(10).to_string(index=False))\n",
    "\n",
    "# ============================================================================\n",
    "# 9. VISUALIZATIONS\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STEP 9: Generating Visualizations\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "sns.set(style=\"whitegrid\", palette=\"tab20\", font_scale=1.1)\n",
    "\n",
    "for grp_name in subgroups.keys():\n",
    "    print(f\"\\n  Creating plots for {grp_name}...\")\n",
    "    \n",
    "    df_grp = metrics_df[metrics_df['Subgroup'] == grp_name]\n",
    "    \n",
    "    # --- MEAN RESIDUALS: BEFORE VS AFTER CALIBRATION ---\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    \n",
    "    x = np.arange(len(df_grp))\n",
    "    width = 0.35\n",
    "    \n",
    "    ax.bar(x - width/2, df_grp['MeanResidual_original'], width, \n",
    "           label='Original', color='coral', alpha=0.8)\n",
    "    ax.bar(x + width/2, df_grp['MeanResidual_calibrated'], width,\n",
    "           label='Calibrated', color='skyblue', alpha=0.8)\n",
    "    \n",
    "    ax.set_xlabel(grp_name, fontsize=12)\n",
    "    ax.set_ylabel('Mean Residual (Pred - True)', fontsize=12)\n",
    "    ax.set_title(f'Bias Reduction: {grp_name}', fontsize=14)\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(df_grp['Category'], rotation=45, ha='right')\n",
    "    ax.axhline(0, color='red', linestyle='--', linewidth=1)\n",
    "    ax.legend()\n",
    "    ax.grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"output/fairness/figures/bias_comparison_{grp_name}.png\", \n",
    "                dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "print(\"\\nâœ“ All visualizations saved\")\n",
    "\n",
    "# ============================================================================\n",
    "# 10. SAVE FINAL OUTPUTS\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STEP 10: Saving Final Outputs\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Save predictions\n",
    "predictions_output = df_test[[\n",
    "    'y_pred_original', \n",
    "    'y_pred_calibrated', \n",
    "    'Residual_original', \n",
    "    'Residual_calibrated'\n",
    "]].copy()\n",
    "predictions_output['y_true'] = y_test.values\n",
    "predictions_output.to_csv(\"output/fairness/tables/predictions_comparison.csv\", index=False)\n",
    "print(\"âœ“ Saved predictions comparison\")\n",
    "\n",
    "# Save calibration adjustments\n",
    "if calibration_applied:\n",
    "    cal_df_list = []\n",
    "    for var_name, bias_dict in calibration_applied.items():\n",
    "        for category, bias_value in bias_dict.items():\n",
    "            cal_df_list.append({\n",
    "                'Variable': var_name,\n",
    "                'Category': category,\n",
    "                'Bias_Correction': bias_value\n",
    "            })\n",
    "    cal_df = pd.DataFrame(cal_df_list)\n",
    "    cal_df.to_csv(\"output/fairness/tables/calibration_adjustments.csv\", index=False)\n",
    "    print(\"âœ“ Saved calibration adjustments\")\n",
    "\n",
    "# ============================================================================\n",
    "# 11. FINAL SUMMARY\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"FAIRNESS ANALYSIS COMPLETE\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\nðŸ“Š Summary:\")\n",
    "print(f\"  â€¢ Test set size: {len(y_test)}\")\n",
    "print(f\"  â€¢ Demographics analyzed: {len(subgroups)}\")\n",
    "print(f\"  â€¢ Variables with significant bias: {len(variables_to_calibrate)}\")\n",
    "print(f\"  â€¢ Calibration applied to: {', '.join(variables_to_calibrate) if variables_to_calibrate else 'None'}\")\n",
    "print(f\"  â€¢ Bootstrap iterations: {N_BOOTSTRAP}\")\n",
    "\n",
    "print(\"\\nðŸ“ Output files saved to:\")\n",
    "print(\"  â€¢ output/fairness/tables/\")\n",
    "print(\"    - bias_detection_results.csv\")\n",
    "print(\"    - calibration_verification.csv\")\n",
    "print(\"    - bootstrap_comparison.csv\")\n",
    "print(\"    - subgroup_metrics.csv\")\n",
    "print(\"    - predictions_comparison.csv\")\n",
    "print(\"    - calibration_adjustments.csv\")\n",
    "print(\"  â€¢ output/fairness/figures/\")\n",
    "print(\"    - bias_comparison_[variable].png (for each demographic)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"âœ… PIPELINE EXECUTION COMPLETE\")\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
